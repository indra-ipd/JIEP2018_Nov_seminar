{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFlearn を使った単層(中間層1層）ニューラルネットワークによる mnist の学習と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4949  | total loss: \u001b[1m\u001b[32m0.01555\u001b[0m\u001b[0m | time: 5.141s\n",
      "| SGD | epoch: 010 | loss: 0.01555 - acc: 0.9973 -- iter: 49400/49500\n",
      "Training Step: 4950  | total loss: \u001b[1m\u001b[32m0.01494\u001b[0m\u001b[0m | time: 6.173s\n",
      "| SGD | epoch: 010 | loss: 0.01494 - acc: 0.9976 | val_loss: 0.07450 - val_acc: 0.9796 -- iter: 49500/49500\n",
      "--\n",
      "学習終了（上記の出力は，fit メソッドがかってに出力しています ⇒ ちょっと表示の詳細がわかりません）\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "import tflearn.datasets.mnist as mnist\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "trainX, trainY, testX, testY = mnist.load_data('/tmp/data', one_hot=True) # tensorflow用　mnist の zip ファイルが有れば展開,無ければDL\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, 784])\n",
    "\n",
    "net = tflearn.fully_connected(net, 128, activation='relu') #ドロップアウト net = tflearn.dropout(net, 0.5) 無し\n",
    "net = tflearn.fully_connected(net, 10, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.5, loss='categorical_crossentropy')\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(trainX, trainY, n_epoch=10, batch_size=100, validation_set=0.1, show_metric=True) # show_metricは,accuracy を毎回示すか否か\n",
    "\n",
    "print('学習終了（上記の出力は，fit メソッドがかってに出力しています ⇒ ちょっと表示の詳細がわかりません．）')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習後の出力（sotfmax の値）と　正解の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1番目のデータの学習結果（softmaxの出力）\n",
      "[1.5359918e-08 3.8843442e-07 1.8704727e-06 9.1617167e-06 3.0096298e-10\n",
      " 2.6328305e-08 2.6477013e-12 9.9998498e-01 5.4484730e-08 3.5832661e-06]\n",
      "1番目のデータの正解\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('1番目のデータの学習結果（softmaxの出力）')\n",
    "soft_max=model.predict(testX)\n",
    "print(soft_max[0])\n",
    "\n",
    "print('1番目のデータの正解')\n",
    "label_No1=testY\n",
    "print(label_No1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータの適用\n",
      "[7 2 1 ... 4 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "正解率： 0.9805\n"
     ]
    }
   ],
   "source": [
    "print('テストデータの適用')\n",
    "\n",
    "x=model.predict(testX)\n",
    "pred=np.array(x).argmax(axis=1) #.argmax は，行方向の何番目が最大値か表示  #pred= np.array(model.predict(testX).argmax(axis=1)) でも同じ\n",
    "print(pred)\n",
    "\n",
    "label= testY.argmax(axis=1) #.argmax は，行方向の何番目が最大値か表示\n",
    "print(label)\n",
    "\n",
    "accuracy=np.mean(pred == label, axis=0) #.argmax は，行方向の何番目が最大値か表示\n",
    "print('正解率：', accuracy)\n",
    "\n",
    "#  .argmax(axis=1)　の意味は以下のとおり．数値は，softmax の出力 ⇒ [7 2 ....]\n",
    "#\n",
    "#  No.1  No.2  ...\n",
    "#  0.01  0.01  ...　⇒”０”\n",
    "#  0.01  0.01  ...　⇒”１”\n",
    "#  0.01  0.8   ...　⇒”２”\n",
    "#  0.01  0.01  ...　⇒”３”\n",
    "#  0.01  0.01  ...　⇒”４”\n",
    "#  0.01  0.01  ...　⇒”５”\n",
    "#  0.01  0.01  ...　⇒”６”\n",
    "#  0.8   0.01  ...　⇒”７”\n",
    "#  0.01  0.01  ...　⇒”８”\n",
    "#  0.12  0.12  ...　⇒”９”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重み（パラメータ）の読み出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00936289 -0.02111606  0.01085935 ... -0.02100659  0.05095698\n",
      "  -0.05719079]\n",
      " [ 0.95485467 -0.7103018   0.46665657 ... -0.29727662  0.02813472\n",
      "  -0.28480673]\n",
      " [-0.0792979  -0.18311383  0.00272807 ... -0.07392094  0.21661812\n",
      "   0.01648906]\n",
      " ...\n",
      " [ 0.08264329  0.30492952  0.09187186 ...  0.6781584  -0.7667123\n",
      "   0.45604545]\n",
      " [ 0.04947324  0.42203814  0.558784   ...  0.5374993  -0.44959804\n",
      "   0.03372763]\n",
      " [-0.34026104  0.12387963 -0.46416128 ...  0.1937358   0.1043925\n",
      "   0.47258824]]\n"
     ]
    }
   ],
   "source": [
    "w = model.get_weights(net.W)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
